{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1118201e-6bc9-491f-a181-5afdb04c575e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Prepare Dataset"
    }
   },
   "outputs": [],
   "source": [
    "mount_path = '/mnt/vision-test'\n",
    "normal_data = f'{mount_path}/gold_dataset_normal'\n",
    "abnormal_data = f'{mount_path}/gold_dataset_abnormal'\n",
    "\n",
    "df_augmented = (\n",
    "    spark.read.parquet(normal_data)\n",
    "    .union(spark.read.parquet(abnormal_data)\n",
    "           )\n",
    ")\n",
    "\n",
    "# display(df_augmented)\n",
    "\n",
    "dataset_name = \"training_dataset_augemented\"\n",
    "df_augmented.write.mode(\"overwrite\").format(\"parquet\").save(f\"{mount_path}/{dataset_name}\")\n",
    "df_augmented.write.mode(\"overwrite\").format(\"delta\").saveAsTable(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a40ebbff-2783-4f55-af9e-5fdc041daa89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "df = spark.read.table(dataset_name)\n",
    "dataset = Dataset.from_spark(df)\n",
    "\n",
    "num_labels = len(dataset.unique('label'))\n",
    "print(f\"{num_labels} labels found in the dataset\")\n",
    "display(dataset)\n",
    "display(dataset.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "853102c3-378c-4ae9-9dfa-842b0f08b1fc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Environment Set Up"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import mlflow.pytorch\n",
    "\n",
    "# Add device selection logic\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device('mps')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f3c13c6-a0a2-45cd-a085-fe89ce965328",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Building Deep Learning"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    AutoModelForImageClassification\n",
    ")\n",
    "\n",
    "# Specify a pre-trained model\n",
    "model_checkpoint = \"google/vit-base-patch16-224\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    use_fast = True,\n",
    "    do_resize= True,\n",
    "    size = 224\n",
    "    )\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=num_labels,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3680a036-8644-45d6-9dad-f46f0274e0dd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Initialize Classifier Weights"
    }
   },
   "outputs": [],
   "source": [
    "model.classifier = torch.nn.Linear(model.config.hidden_size, num_labels)\n",
    "torch.nn.init.xavier_uniform_(model.classifier.weight)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5a0a0b9-5fbc-4524-adf7-d69d4f201e08",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Process Input(Image)"
    }
   },
   "outputs": [],
   "source": [
    "# Define a preprocessing function to handle binary inmage data\n",
    "\n",
    "def preprocess(example):\n",
    "    # Convert binary image data to PIL Image with RGB channel\n",
    "    image = Image.open(io.BytesIO(example['image'])).convert(\"RGB\")\n",
    "\n",
    "    # Process the image using the image processor\n",
    "    processed_image = image_processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "    # [1,3,224,224] -> [3,224,224]\n",
    "    example['pixel_values'] = processed_image['pixel_values'].squeeze()\n",
    "    example['pixel_values'] = example['pixel_values'].to(device)\n",
    "    return example\n",
    "\n",
    "# Apply the preprocessing function to the dataset\n",
    "dataset = dataset.map(preprocess)\n",
    "\n",
    "# Set the format of dataset to PyTorch Tensors\n",
    "dataset.set_format(type='torch', columns=['pixel_values', 'label'])\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = dataset['train']\n",
    "eval_dataset = dataset['test']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e92791f-db95-478d-a3e3-6ea4e55c891c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_ds_abnormal = len(train_dataset['label'][train_dataset['label'] == 0])\n",
    "train_ds_normal = len(train_dataset['label'][train_dataset['label'] == 1])\n",
    "eval_ds_abnormal = len(eval_dataset['label'][eval_dataset['label'] == 0])\n",
    "eval_ds_normal = len(eval_dataset['label'][eval_dataset['label'] == 1])\n",
    "\n",
    "print(f\"Training dataset: {train_ds_abnormal} abnormal, {train_ds_normal} normal\")\n",
    "print(f\"Eval dataset: {eval_ds_abnormal} abnormal, {eval_ds_normal} normal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfc3bfb6-27e2-418d-ac97-5482391b25a7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Training Set up"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "import os# Set environment vairables to avoid the warning\n",
    "os.environ['OMP_NUM_THREADS'] = '16'\n",
    "os.environ['MKL_NUM_THREADS'] ='16'\n",
    "\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"/tmp/huggingface/{model_name}-finetuned-dog\",\n",
    "    remove_unused_columns=False,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    gradient_accumulation_steps=1,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    ddp_find_unused_parameters=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d3da556-f24c-498a-9d8a-91af33a39889",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Evaluation Metrics"
    }
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbc8aca7-e988-4eef-a4e4-76c327c327d5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Train(MLflow)"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, EarlyStoppingCallback\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "# Start an MLflow run\n",
    "run_name = f\"vit-classification-{time.strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    early_stop = EarlyStoppingCallback(early_stopping_patience=5)\n",
    "    \n",
    "    # Initialize\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[early_stop]\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    train_result = trainer.train()\n",
    "\n",
    "\n",
    "    # Log training metrics\n",
    "    mlflow.log_metrics(train_result.metrics)\n",
    "\n",
    "    # Evaluate and log metrics\n",
    "    eval_metrics = trainer.evaluate()\n",
    "    mlflow.log_metrics(eval_metrics)\n",
    "\n",
    "\n",
    "    # Get a sample input and prepare it for signature\n",
    "    sample_input = next(iter(eval_dataset))\n",
    "    input_tensor = sample_input['pixel_values'].unsqueeze(0) #[-1,3,224,224]\n",
    "\n",
    "    # Get model prediction for signature\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        sample_output = model(input_tensor)\n",
    "    \n",
    "    # Convert to numpy arrays for MLflow\n",
    "    input_array = input_tensor.cpu().numpy()\n",
    "    output_array = sample_output.logits.cpu().numpy()\n",
    "\n",
    "    # Create signature\n",
    "    signature = infer_signature(input_array, output_array)\n",
    "\n",
    "    # Log requirements\n",
    "    reqs = mlflow.transformers.get_default_pip_requirements(model)\n",
    "\n",
    "    # Log the model with MLflow\n",
    "    mlflow.pytorch.log_model(\n",
    "        pytorch_model = model,\n",
    "        artifact_path = 'model',\n",
    "        signature = signature,\n",
    "        pip_requirements = reqs\n",
    "        )\n",
    "\n",
    "    \n",
    "    # Log the input dataset for lineage tracking from table to model\n",
    "    src_dataset = mlflow.data.load_delta(\n",
    "        table_name = dataset_name\n",
    "    )\n",
    "    mlflow.log_input(src_dataset, context='Training-Input')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_HF_Deep_Learning",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
