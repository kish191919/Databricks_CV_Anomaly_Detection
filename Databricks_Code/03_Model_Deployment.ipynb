{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98b81ce0-15e2-43fa-a660-6ed9d753b4d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "import io\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from pyspark.sql.functions import col\n",
    "from PIL import Image\n",
    "\n",
    "def proprocess(example):\n",
    "    \"\"\"Convert binary image to a tensor of shape (3,224,224)\"\"\"\n",
    "    image = Image.open(io.BytesIO(example['image'])).convert('RGB')\n",
    "    \n",
    "    ### Auto Image Processor ###\n",
    "    # 1. resize\n",
    "    image = image.resize((224,224)) #[224,224,3]\n",
    "    \n",
    "    # 2. Convert to Numpy array and normalize\n",
    "    image_array = np.array(image, dtype=np.float32) / 255.0\n",
    "    \n",
    "    # 3. Transpose [224,224,3] -> [3,224,224]\n",
    "    image_array = image_array.transpose(2,0,1)\n",
    "\n",
    "    # Store as a PyTorch Tensor instead of a list\n",
    "    example['pixel_values'] = torch.tensor(image_array, dtype=torch.float32)\n",
    "\n",
    "    return example\n",
    "\n",
    "dataset_name = 'training_dataset_augemented'\n",
    "normal_samples = (\n",
    "    spark.read.table(dataset_name)\n",
    "    .filter(col('label')==1)\n",
    "    .select('image', 'label')\n",
    "    .limit(5)\n",
    ")\n",
    "\n",
    "# Spark DataFrame -> Hugging Face Dataset\n",
    "normal_samples = Dataset.from_spark(normal_samples)\n",
    "data = normal_samples.map(proprocess)\n",
    "\n",
    "# Extract tensors and stack them\n",
    "pixel_values_list = [torch.tensor(example['pixel_values']) for example in data]\n",
    "input_tensor = torch.stack(pixel_values_list)\n",
    "\n",
    "# print('First pixel_values_list :', pixel_values_list[0])\n",
    "print('First pixel_values_list shape :', pixel_values_list[0].shape)\n",
    "print(f'Final input tensor shape: {input_tensor.shape}') #(5,3,224,224)\n",
    "\n",
    "\n",
    "# Load modle and move it to appropriate device(cpu)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_uri = 'runs:/feb6fb0cef6b40aeb2f4261329c8c3f9/model'\n",
    "model = mlflow.pytorch.load_model(model_uri).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Move input tensor to device and make prediction\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(input_tensor)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec89ec58-2ab6-4347-a846-6dc48e4de577",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Print output shape and predictions\n",
    "print(f\"output predictions: {predictions}\")\n",
    "print(f\"Predictions.logits : {predictions.logits.shape} \\n{predictions.logits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4be6dcf3-1808-4f24-b6f9-b41a8fc355fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Class 0 -> \"abnormal\"\n",
    "# Class 1 -> \"normal\"\n",
    "\n",
    "# Apply softmax to get probabilities\n",
    "probabilities = F.softmax(predictions.logits, dim=1)\n",
    "print(f\"Probabilities: {probabilities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81053f35-58c6-4f58-8d74-8dd4b19413a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_Model_Deployment",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
