{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98b81ce0-15e2-43fa-a660-6ed9d753b4d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5231d8d9a5841cb91d777377bdbcf56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First pixel_values_list shape : torch.Size([3, 224, 224])\nFinal input tensor shape: torch.Size([5, 3, 224, 224])\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3472c3732243d9ac6c9b01301757c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-14 12:18:22.270592: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-09-14 12:18:22.459271: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n2025-09-14 12:18:22.660419: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-09-14 12:18:22.820214: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-09-14 12:18:22.868759: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-09-14 12:18:23.178425: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2025-09-14 12:18:25.584730: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageClassifierOutput(loss=None, logits=tensor([[-1.0475,  0.7031],\n        [ 0.4886,  2.9053],\n        [-0.8897,  1.4195],\n        [-1.6510,  1.9711],\n        [-1.9251,  0.6765]]), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "import io\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from pyspark.sql.functions import col\n",
    "from PIL import Image\n",
    "\n",
    "def proprocess(example):\n",
    "    \"\"\"Convert binary image to a tensor of shape (3,224,224)\"\"\"\n",
    "    image = Image.open(io.BytesIO(example['image'])).convert('RGB')\n",
    "    \n",
    "    ### Auto Image Processor ###\n",
    "    # 1. resize\n",
    "    image = image.resize((224,224)) #[224,224,3]\n",
    "    \n",
    "    # 2. Convert to Numpy array and normalize\n",
    "    image_array = np.array(image, dtype=np.float32) / 255.0\n",
    "    \n",
    "    # 3. Transpose [224,224,3] -> [3,224,224]\n",
    "    image_array = image_array.transpose(2,0,1)\n",
    "\n",
    "    # Store as a PyTorch Tensor instead of a list\n",
    "    example['pixel_values'] = torch.tensor(image_array, dtype=torch.float32)\n",
    "\n",
    "    return example\n",
    "\n",
    "dataset_name = 'training_dataset_augemented'\n",
    "normal_samples = (\n",
    "    spark.read.table(dataset_name)\n",
    "    .filter(col('label')==1)\n",
    "    .select('image', 'label')\n",
    "    .limit(5)\n",
    ")\n",
    "\n",
    "# Spark DataFrame -> Hugging Face Dataset\n",
    "normal_samples = Dataset.from_spark(normal_samples)\n",
    "data = normal_samples.map(proprocess)\n",
    "\n",
    "# Extract tensors and stack them\n",
    "pixel_values_list = [torch.tensor(example['pixel_values']) for example in data]\n",
    "input_tensor = torch.stack(pixel_values_list)\n",
    "\n",
    "# print('First pixel_values_list :', pixel_values_list[0])\n",
    "print('First pixel_values_list shape :', pixel_values_list[0].shape)\n",
    "print(f'Final input tensor shape: {input_tensor.shape}') #(5,3,224,224)\n",
    "\n",
    "\n",
    "# Load modle and move it to appropriate device(cpu)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_uri = 'runs:/feb6fb0cef6b40aeb2f4261329c8c3f9/model'\n",
    "model = mlflow.pytorch.load_model(model_uri).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Move input tensor to device and make prediction\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(input_tensor)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec89ec58-2ab6-4347-a846-6dc48e4de577",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output predictions: ImageClassifierOutput(loss=None, logits=tensor([[-1.0475,  0.7031],\n        [ 0.4886,  2.9053],\n        [-0.8897,  1.4195],\n        [-1.6510,  1.9711],\n        [-1.9251,  0.6765]]), hidden_states=None, attentions=None)\nPredictions.logits : torch.Size([5, 2]) \ntensor([[-1.0475,  0.7031],\n        [ 0.4886,  2.9053],\n        [-0.8897,  1.4195],\n        [-1.6510,  1.9711],\n        [-1.9251,  0.6765]])\n"
     ]
    }
   ],
   "source": [
    "# Print output shape and predictions\n",
    "print(f\"output predictions: {predictions}\")\n",
    "print(f\"Predictions.logits : {predictions.logits.shape} \\n{predictions.logits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4be6dcf3-1808-4f24-b6f9-b41a8fc355fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: tensor([[0.1480, 0.8520],\n        [0.0819, 0.9181],\n        [0.0904, 0.9096],\n        [0.0260, 0.9740],\n        [0.0690, 0.9310]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Class 0 -> \"abnormal\"\n",
    "# Class 1 -> \"normal\"\n",
    "\n",
    "# Apply softmax to get probabilities\n",
    "probabilities = F.softmax(predictions.logits, dim=1)\n",
    "print(f\"Probabilities: {probabilities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81053f35-58c6-4f58-8d74-8dd4b19413a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_Model_Deployment",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}